{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5915171e-25b8-4674-882f-7102415d1df5",
   "metadata": {},
   "source": [
    "# Testing False Positives of Benign Flight\n",
    "This notebook looks at false positive rates in the benign case by using a set\n",
    "of 5 flights where 4 determine the error bounds and 1 is used for testing.\n",
    "\n",
    "The data files can be found in the data subdirectory. Only interim data will be\n",
    "available on github to preserve storage. For raw log files please contact me at\n",
    "srimoungchanh.bailey@ku.edu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4b1f4c-4f65-4a1b-9557-5bf7e7b7eb46",
   "metadata": {},
   "source": [
    "# Optical Flow and GPS Velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fae325-6023-434d-be33-22d5297a9f71",
   "metadata": {},
   "source": [
    "## Loading Data and Parsing Error Margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "615b0cfc-7ec1-4349-a244-5a58d29aacbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from confirmation.process import process_SNS\n",
    "from os.path import exists\n",
    "from confirmation.process import geodetic2ned, change_in_signal\n",
    "from confirmation.process import length, body_to_earth2D, low_pass_filter\n",
    "from confirmation.process import signal_match_and_cumsum\n",
    "\n",
    "#Data used for comparisons later\n",
    "max_errors = []\n",
    "errors_north = []\n",
    "errors_east = []\n",
    "total_diff = []\n",
    "\n",
    "#Convert log file from Mission Planner to usable CSV\n",
    "data_dir = \"../data/\"\n",
    "files = [\"2023-01-26-Delivery (\" + str(x) + \").log\" for x in range(1, 6)] #list of files to process\n",
    "\n",
    "for file in files:\n",
    "    output = data_dir + \"interim/\" + file[:-3] + \"csv\"\n",
    "\n",
    "    #Check if file exists already and if it does skip processing and read the file\n",
    "    if not exists(output):\n",
    "        #Open log file and parse out the SNS data into pandas dataframes\n",
    "        df = process_SNS(data_dir + \"raw/\" + file, output)\n",
    "    else:\n",
    "        df = pd.read_csv(output)\n",
    "\n",
    "    #All of the data is numeric and should be treated as such\n",
    "    df = df.apply(pd.to_numeric)\n",
    "\n",
    "    #Set index to be the timestamps so we can drop duplicate rows\n",
    "    #then reset index to be row number\n",
    "    df.set_index(\"TimeUS\",inplace=True)\n",
    "    df = df.drop_duplicates()\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    #Get rid of duplicate rows and convert timestamps to datetime\n",
    "    ofMS = df[df.ofMS.shift() != df.ofMS][[\"ofMS\",\"frF\",\"frR\",\"brF\",\"brR\", \"rf\", \"m00\", \"m10\"]].reset_index()\n",
    "    ofMS['ofMS'] = pd.to_datetime(ofMS['ofMS'], unit='ms')\n",
    "    gpsMS = df[df.gpsMS.shift() != df.gpsMS][[\"gpsMS\",\"lat\",\"lng\",\"gpAlt\", \"m00\", \"m10\"]].reset_index()\n",
    "    gpsMS['gpsMS'] = pd.to_datetime(gpsMS['gpsMS'], unit='ms')\n",
    "    rfMS = df[df.rfMS.shift() != df.rfMS][[\"rfMS\",\"rf\",\"m22\"]].reset_index(drop=True)\n",
    "    rfMS['rfMS'] = pd.to_datetime(rfMS['rfMS'], unit='ms')\n",
    "    \n",
    "    #GPS Velocity\n",
    "    gps = geodetic2ned(gpsMS.lat, gpsMS.lng, gpsMS.gpAlt)\n",
    "    gps_north = (gps.North.diff().fillna(0)/(gpsMS.gpsMS.diff().dt.total_seconds()))[1:].reset_index(drop=True)\n",
    "    gps_east = (gps.East.diff().fillna(0)/(gpsMS.gpsMS.diff().dt.total_seconds()))[1:].reset_index(drop=True)\n",
    "    gps_down = (gps.Down.diff().fillna(0)/100/(gpsMS.gpsMS.diff().dt.total_seconds()))[1:].reset_index(drop=True)\n",
    "\n",
    "    gps_east = pd.Series(gps_east)\n",
    "    gps_north = pd.Series(gps_north)\n",
    "    \n",
    "    #Convert optical flow and rangefinder to OF Velocity in body frame\n",
    "    of_vel_bf = pd.DataFrame(data={\"OF Forward\":(ofMS.frF - ofMS.brF) * ofMS.rf/100,\n",
    "                                   \"OF Right\":(ofMS.frR - ofMS.brR) * ofMS.rf/100})\n",
    "    earth_frame = body_to_earth2D(of_vel_bf[\"OF Forward\"], of_vel_bf[\"OF Right\"], ofMS.m00, ofMS.m10)\n",
    "    \n",
    "    lpf_E = -low_pass_filter(earth_frame.East, alpha=0.2)\n",
    "    lpf_N = low_pass_filter(earth_frame.North, alpha=0.2)\n",
    "    \n",
    "    gps_east = pd.Series(gps_east)\n",
    "    lpf_E = pd.Series(lpf_E)\n",
    "    gps_north = pd.Series(gps_north)\n",
    "    lpf_N = pd.Series(lpf_N)\n",
    "    \n",
    "    #Matching OF to the GPS update rate\n",
    "    of_east = signal_match_and_cumsum(ofMS.ofMS.diff().dt.total_seconds().fillna(0).cumsum()[1:].reset_index(drop=True), change_in_signal(lpf_E),\n",
    "                                      gpsMS.gpsMS.diff().dt.total_seconds().fillna(0).cumsum(), gps_east)\n",
    "    of_east = pd.Series(of_east, name=\"OF East, LPF\")\n",
    "    of_north = signal_match_and_cumsum(ofMS.ofMS.diff().dt.total_seconds().fillna(0).cumsum()[1:].reset_index(drop=True), change_in_signal(lpf_N),\n",
    "                                       gpsMS.gpsMS.diff().dt.total_seconds().fillna(0).cumsum(), gps_north)\n",
    "    of_north = pd.Series(of_north, name=\"OF North, LPF\")\n",
    "    \n",
    "    diff_east = abs(gps_east - of_east)\n",
    "    diff_north = abs(gps_north - of_north)\n",
    "    diff = pd.Series([((x**2) + (y**2))**(1/2) for x,y in zip(diff_east, diff_north)])\n",
    "    max_errors.append(np.nanmax(diff))\n",
    "    errors_north.append(diff_north)\n",
    "    errors_east.append(diff_east)\n",
    "    total_diff.append(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62da8922-5bb0-4e9b-a279-9a2911735d92",
   "metadata": {},
   "source": [
    "## Approach #1, Error Margin from 4 flights, Test on 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3a11bc3-aef4-4e3b-b255-b80518159f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#key is the mission being tested by error derived from the other 4\n",
    "false_positives = {0:0,\n",
    "                   1:0,\n",
    "                   2:0,\n",
    "                   3:0,\n",
    "                   4:0}\n",
    "\n",
    "for error in range(len(max_errors)):\n",
    "    max_bound = 0\n",
    "    for others in range(len(max_errors)): #Find the largest error amongst the other 4 tests\n",
    "        if others == error:\n",
    "            continue\n",
    "        max_bound = max(max_bound, max_errors[others])\n",
    "    false_positives[error] = len(total_diff[error][total_diff[error] >= max_bound])/len(total_diff[error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6112ff90-4636-4011-9a9d-e822d7be7186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.0, 1: 0.007722007722007722, 2: 0.0, 3: 0.0, 4: 0.0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99187f42-89c6-4564-9a42-ef0529953e58",
   "metadata": {},
   "source": [
    "## Approach #2, Error Margin from 1 flight, Tested against 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8886401e-6c79-4441-9e95-7b54a3281829",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first key is where the error bound comes from,\n",
    "#nested keys are the mission being tested\n",
    "false_positives = {0:{1:0, 2:0, 3:0, 4:0},\n",
    "                   1:{0:0, 2:0, 3:0, 4:0},\n",
    "                   2:{0:0, 1:0, 3:0, 4:0},\n",
    "                   3:{0:0, 1:0, 2:0, 4:0},\n",
    "                   4:{0:0, 1:0, 2:0, 3:0}}\n",
    "\n",
    "for error in range(len(max_errors)): #Assign max error of test to bound\n",
    "    bound = max_errors[error]\n",
    "    for others in range(len(max_errors)): #False positives for other tests using bound\n",
    "        if others == error:\n",
    "            continue\n",
    "        false_positives[error][others] = len(total_diff[others][total_diff[others] >= bound])/len(total_diff[others])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c68b920-ed60-4949-bd85-5824a3c17451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {1: 0.019305019305019305,\n",
      "     2: 0.01556420233463035,\n",
      "     3: 0.09170305676855896,\n",
      "     4: 0.023166023166023165},\n",
      " 1: {0: 0.0, 2: 0.0, 3: 0.0, 4: 0.0},\n",
      " 2: {0: 0.0,\n",
      "     1: 0.011583011583011582,\n",
      "     3: 0.017467248908296942,\n",
      "     4: 0.007722007722007722},\n",
      " 3: {0: 0.0, 1: 0.007722007722007722, 2: 0.0, 4: 0.003861003861003861},\n",
      " 4: {0: 0.0, 1: 0.007722007722007722, 2: 0.0, 3: 0.0}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(false_positives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d63ba7b-aa90-4e21-a5a5-f3db6c34b601",
   "metadata": {},
   "source": [
    "# Gyroscope Yaw and GPS Ground Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2a8c120-5bdf-4845-9e02-297549dddba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import degrees, atan2\n",
    "from confirmation.process import trap_integrate, diff\n",
    "\n",
    "#Data used for comparisons later\n",
    "max_errors = []\n",
    "total_diff = []\n",
    "\n",
    "#Valid mission times since GPS isn't usable unless in flight\n",
    "timings = [[237000000, 281000000],\n",
    "           [86000000, 121000000],\n",
    "           [108000000,152000000],\n",
    "           [247000000,284000000],\n",
    "           [101000000,145000000]]\n",
    "\n",
    "#Convert log file from Mission Planner to usable CSV\n",
    "data_dir = \"../data/\"\n",
    "files = [\"2023-01-26-Delivery (\" + str(x) + \").log\" for x in range(1, 6)] #list of files to process\n",
    "\n",
    "for index in range(len(files)):\n",
    "    file = files[index]\n",
    "    output = data_dir + \"interim/\" + file[:-3] + \"csv\"\n",
    "\n",
    "    #Check if file exists already and if it does skip processing and read the file\n",
    "    if not exists(output):\n",
    "        #Open log file and parse out the SNS data into pandas dataframes\n",
    "        df = process_SNS(data_dir + \"raw/\" + file, output)\n",
    "    else:\n",
    "        df = pd.read_csv(output)\n",
    "\n",
    "    #All of the data is numeric and should be treated as such\n",
    "    df = df.apply(pd.to_numeric)\n",
    "\n",
    "    #Set index to be the timestamps so we can drop duplicate rows\n",
    "    #then reset index to be row number\n",
    "    df = df[(df.TimeUS >= timings[index][0]) & (df.TimeUS <= timings[index][1])]\n",
    "    df.set_index(\"TimeUS\",inplace=True)\n",
    "    df = df.drop_duplicates()\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    #Get rid of duplicate rows and convert timestamps to datetime\n",
    "    cUS = df[df.cUS.shift() != df.cUS][[\"cUS\",\"gyrx\",\"gyry\",\"gyrz\",\"CAN\",\"CAE\",\"CAD\",\"rCAN\",\"rCAE\",\"rCAD\", \"CVN\", \"CVE\", \"CVD\"]].reset_index()\n",
    "    cUS['cUS'] = pd.to_datetime(cUS['cUS'], unit='us')\n",
    "    gpsMS = df[df.gpsMS.shift() != df.gpsMS][[\"gpsMS\",\"lat\",\"lng\",\"gpAlt\", \"m00\", \"m10\"]].reset_index()\n",
    "    gpsMS['gpsMS'] = pd.to_datetime(gpsMS['gpsMS'], unit='ms')\n",
    "    \n",
    "    #GPS Velocity\n",
    "    gps = geodetic2ned(gpsMS.lat, gpsMS.lng, gpsMS.gpAlt)\n",
    "    gps_north = (gps.North.diff().fillna(0)/(gpsMS.gpsMS.diff().dt.total_seconds()))[1:].reset_index(drop=True)\n",
    "    gps_east = (gps.East.diff().fillna(0)/(gpsMS.gpsMS.diff().dt.total_seconds()))[1:].reset_index(drop=True)\n",
    "    gps_down = (gps.Down.diff().fillna(0)/100/(gpsMS.gpsMS.diff().dt.total_seconds()))[1:].reset_index(drop=True)\n",
    "\n",
    "    gps_east = pd.Series(gps_east)\n",
    "    gps_north = pd.Series(gps_north)\n",
    "\n",
    "    #GPS derived ground course\n",
    "    gps_gc = []\n",
    "    for reading in range(len(gps_north)):\n",
    "        gps_gc.append(degrees(atan2(gps_east[reading], gps_north[reading])) % 360)\n",
    "    gps_gc = pd.Series(gps_gc, name=\"GPS Ground Course\")\n",
    "\n",
    "    #Matching gyroscope to the GPS update rate\n",
    "    gyr_heading = trap_integrate(cUS.cUS.diff().dt.total_seconds().fillna(0).cumsum(), cUS.gyrz).apply(degrees).cumsum() % 360\n",
    "    gyr_gps_heading = signal_match_and_cumsum(cUS.cUS.diff().dt.total_seconds().fillna(0).cumsum()[2:].reset_index(drop=True), change_in_signal(gyr_heading),\n",
    "                                              gpsMS.gpsMS.diff().dt.total_seconds().fillna(0).cumsum(), gps_gc)\n",
    "    gyr_gps_heading = pd.Series(gyr_gps_heading, name=\"Gyroscope Heading\")\n",
    "    \n",
    "    #Start both signals at 0 to align them\n",
    "    gps_gc = (gps_gc - gps_gc[0]) % 360\n",
    "    gyr_gps_heading = (gyr_gps_heading - gyr_gps_heading[0])%360\n",
    "\n",
    "    angle_diff = abs(diff(gps_gc[1:].reset_index(drop=True), gyr_gps_heading, wrap=True))\n",
    "    max_errors.append(np.nanmax(angle_diff))\n",
    "    total_diff.append(angle_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c51791d-6d27-4c02-8c68-40e04746c91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13.963222381629436,\n",
       " 9.802613871891424,\n",
       " 11.192658744241498,\n",
       " 13.242882067339167,\n",
       " 10.1471880109533]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb8cce9-9bd7-46c5-84b1-e34168df94f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
