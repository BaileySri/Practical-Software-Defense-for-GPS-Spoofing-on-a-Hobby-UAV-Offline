{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5915171e-25b8-4674-882f-7102415d1df5",
   "metadata": {},
   "source": [
    "# Testing False Positives of Benign Flight\n",
    "This notebook looks at false positive rates in the benign case by using a set\n",
    "of 5 flights where 4 determine the error bounds and 1 is used for testing.\n",
    "\n",
    "The data files can be found in the data subdirectory. Only interim data will be\n",
    "available on github to preserve storage. For raw log files please contact me at\n",
    "srimoungchanh.bailey@ku.edu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fae325-6023-434d-be33-22d5297a9f71",
   "metadata": {},
   "source": [
    "## Loading Data and Parsing Error Margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "615b0cfc-7ec1-4349-a244-5a58d29aacbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from confirmation.process import process_SNS\n",
    "from os.path import exists\n",
    "from confirmation.process import geodetic2ned, change_in_signal\n",
    "from confirmation.process import length, body_to_earth2D, low_pass_filter\n",
    "from confirmation.process import signal_match_and_cumsum\n",
    "\n",
    "#Data used for comparisons later\n",
    "max_errors = []\n",
    "errors_north = []\n",
    "errors_east = []\n",
    "\n",
    "#Convert log file from Mission Planner to usable CSV\n",
    "data_dir = \"../data/\"\n",
    "files = [\"2023-01-26-Delivery (\" + str(x) + \").log\" for x in range(1, 6)] #list of files to process\n",
    "\n",
    "for file in files:\n",
    "    output = data_dir + \"interim/\" + file[:-3] + \"csv\"\n",
    "\n",
    "    #Check if file exists already and if it does skip processing and read the file\n",
    "    if not exists(output):\n",
    "        #Open log file and parse out the SNS data into pandas dataframes\n",
    "        df = process_SNS(data_dir + \"raw/\" + file, output)\n",
    "    else:\n",
    "        df = pd.read_csv(output)\n",
    "\n",
    "    #All of the data is numeric and should be treated as such\n",
    "    df = df.apply(pd.to_numeric)\n",
    "\n",
    "    #Set index to be the timestamps so we can drop duplicate rows\n",
    "    #then reset index to be row number\n",
    "    df.set_index(\"TimeUS\",inplace=True)\n",
    "    df = df.drop_duplicates()\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    #Get rid of duplicate rows and convert timestamps to datetime\n",
    "    ofMS = df[df.ofMS.shift() != df.ofMS][[\"ofMS\",\"frF\",\"frR\",\"brF\",\"brR\", \"rf\", \"m00\", \"m10\"]].reset_index()\n",
    "    ofMS['ofMS'] = pd.to_datetime(ofMS['ofMS'], unit='ms')\n",
    "    gpsMS = df[df.gpsMS.shift() != df.gpsMS][[\"gpsMS\",\"lat\",\"lng\",\"gpAlt\", \"m00\", \"m10\"]].reset_index()\n",
    "    gpsMS['gpsMS'] = pd.to_datetime(gpsMS['gpsMS'], unit='ms')\n",
    "    rfMS = df[df.rfMS.shift() != df.rfMS][[\"rfMS\",\"rf\",\"m22\"]].reset_index(drop=True)\n",
    "    rfMS['rfMS'] = pd.to_datetime(rfMS['rfMS'], unit='ms')\n",
    "    \n",
    "    \n",
    "\n",
    "    gps = geodetic2ned(gpsMS.lat, gpsMS.lng, gpsMS.gpAlt)\n",
    "    gps_north = gps.North.diff().fillna(0)/(gpsMS.gpsMS.diff().dt.total_seconds())\n",
    "    gps_east = gps.East.diff().fillna(0)/(gpsMS.gpsMS.diff().dt.total_seconds())\n",
    "    gps_down = gps.Down.diff().fillna(0)/100/(gpsMS.gpsMS.diff().dt.total_seconds())\n",
    "    \n",
    "    #Convert optical flow and rangefinder to OF Velocity in body frame\n",
    "    of_vel_bf = pd.DataFrame(data={\"OF Forward\":(ofMS.frF - ofMS.brF) * ofMS.rf/100,\n",
    "                                   \"OF Right\":(ofMS.frR - ofMS.brR) * ofMS.rf/100})\n",
    "    earth_frame = body_to_earth2D(of_vel_bf[\"OF Forward\"], of_vel_bf[\"OF Right\"], ofMS.m00, ofMS.m10)\n",
    "    \n",
    "    lpf_E = -low_pass_filter(earth_frame.East, alpha=0.2)\n",
    "    lpf_N = low_pass_filter(earth_frame.North, alpha=0.2)\n",
    "    \n",
    "    gps_east = pd.Series(gps_east)\n",
    "    lpf_E = pd.Series(lpf_E)\n",
    "    gps_north = pd.Series(gps_north)\n",
    "    lpf_N = pd.Series(lpf_N)\n",
    "    \n",
    "    \n",
    "    #Matching OF to the GPS update rate\n",
    "    of_east = signal_match_and_cumsum(ofMS.ofMS.diff().dt.total_seconds().fillna(0).cumsum()[1:].reset_index(drop=True), change_in_signal(lpf_E),\n",
    "                                      gpsMS.gpsMS.diff().dt.total_seconds().fillna(0).cumsum(), gps_east)\n",
    "    of_east = pd.Series(of_east, name=\"OF East, LPF\")\n",
    "    of_north = signal_match_and_cumsum(ofMS.ofMS.diff().dt.total_seconds().fillna(0).cumsum()[1:].reset_index(drop=True), change_in_signal(lpf_N),\n",
    "                                       gpsMS.gpsMS.diff().dt.total_seconds().fillna(0).cumsum(), gps_north)\n",
    "    of_north = pd.Series(of_north, name=\"OF North, LPF\")\n",
    "    \n",
    "    diff_north = abs(gps_north - of_north)\n",
    "    diff_east = abs(gps_east - of_east)\n",
    "    max_errors.append(max(diff_north.max(), diff_east.max()))\n",
    "    errors_north.append(diff_north)\n",
    "    errors_east.append(diff_east)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62da8922-5bb0-4e9b-a279-9a2911735d92",
   "metadata": {},
   "source": [
    "## Approach #1, Error Margin from 4 flights, Test on 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3a11bc3-aef4-4e3b-b255-b80518159f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#key is the mission being tested by error derived from the other 4\n",
    "false_positives = {0:0,\n",
    "                   1:0,\n",
    "                   2:0,\n",
    "                   3:0,\n",
    "                   4:0}\n",
    "\n",
    "for error in range(len(max_errors)):\n",
    "    bound = max_errors[error]\n",
    "    max_bound = 0\n",
    "    for others in range(len(max_errors)):\n",
    "        if others == error:\n",
    "            continue\n",
    "        max_bound = max(max_bound, max_errors[others])\n",
    "    false_positives[error] = len(errors_east[error][errors_east[error] >= max_bound].index.union(errors_north[error][errors_north[error] >= max_bound]))/len(errors_east[error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6112ff90-4636-4011-9a9d-e822d7be7186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.0, 1: 0.0038461538461538464, 2: 0.0, 3: 0.0, 4: 0.0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99187f42-89c6-4564-9a42-ef0529953e58",
   "metadata": {},
   "source": [
    "## Approach #2, Error Margin from 1 flight, Tested against 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8886401e-6c79-4441-9e95-7b54a3281829",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first key is where the error bound comes from,\n",
    "#nested keys are the mission being tested\n",
    "false_positives = {0:{1:0, 2:0, 3:0, 4:0},\n",
    "                   1:{0:0, 2:0, 3:0, 4:0},\n",
    "                   2:{0:0, 1:0, 3:0, 4:0},\n",
    "                   3:{0:0, 1:0, 2:0, 4:0},\n",
    "                   4:{0:0, 1:0, 2:0, 3:0}}\n",
    "\n",
    "for error in range(len(max_errors)):\n",
    "    bound = max_errors[error]\n",
    "    for others in range(len(max_errors)):\n",
    "        if others == error:\n",
    "            continue\n",
    "        east_fp = errors_east[others][errors_east[others] >= bound].index\n",
    "        north_fp = errors_north[others][errors_north[others] >= bound].index\n",
    "        false_positives[error][others] = len(east_fp.union(north_fp))/len(errors_east[others])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c68b920-ed60-4949-bd85-5824a3c17451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {1: 0.011538461538461539,\n",
      "     2: 0.011673151750972763,\n",
      "     3: 0.05627705627705628,\n",
      "     4: 0.019305019305019305},\n",
      " 1: {0: 0.0, 2: 0.0, 3: 0.0, 4: 0.0},\n",
      " 2: {0: 0.0, 1: 0.011538461538461539, 3: 0.0, 4: 0.003861003861003861},\n",
      " 3: {0: 0.0,\n",
      "     1: 0.011538461538461539,\n",
      "     2: 0.0038910505836575876,\n",
      "     4: 0.003861003861003861},\n",
      " 4: {0: 0.0, 1: 0.0038461538461538464, 2: 0.0, 3: 0.0}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(false_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff898763-3c85-4355-9727-bd7b1822d507",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
